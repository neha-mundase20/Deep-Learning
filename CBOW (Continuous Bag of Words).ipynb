{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e021ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coffee', 'trees', 'are', 'pruned', 'short', 'to', 'conserve', 'their', 'energy', 'and', 'aid', 'in', 'harvesting', 'but', 'can', 'grow', 'to', 'more', 'than', '30', 'feet', '9', 'meters', 'high', 'each', 'tree', 'is', 'covered', 'with', 'green', 'waxy', 'leaves', 'growing', 'opposite', 'each', 'other', 'in', 'pairs', 'coffee', 'cherries', 'grow', 'along', 'the', 'branches', 'because', 'it', 'grows', 'in', 'a', 'continuous', 'cycle', 'it', 's', 'not', 'unusual', 'to', 'see', 'flowers', 'green', 'fruit', 'and', 'ripe', 'fruit', 'simultaneously', 'on', 'a', 'single', 'tree', 'all', 'commercially', 'grown', 'coffee', 'is', 'from', 'a', 'region', 'of', 'the', 'world', 'called', 'the', 'coffee', 'belt', 'the', 'trees', 'grow', 'best', 'in', 'rich', 'soil', 'with', 'mild', 'temperatures', 'frequent', 'rain', 'and', 'shaded', 'sun']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Read and clean document\n",
    "with open(\"t1.txt\", \"r\") as f:\n",
    "    doc1 = f.read().lower()\n",
    "l_doc1 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc1).split()\n",
    "print(l_doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3cd130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Calculation: \n",
      "\n",
      "{'along': 1, 'are': 1, 'waxy': 1, 'soil': 1, 'continuous': 1, 'belt': 1, 'high': 1, 'shaded': 1, 'covered': 1, 'rain': 1, 'rich': 1, 'harvesting': 1, 'the': 4, 'their': 1, 'coffee': 4, 'frequent': 1, 'than': 1, 'growing': 1, 'leaves': 1, 'opposite': 1, 'and': 3, 'unusual': 1, 'see': 1, 'fruit': 2, 'mild': 1, '9': 1, 'conserve': 1, '30': 1, 'it': 2, 'pairs': 1, 'grow': 3, 'to': 3, 'tree': 2, 'commercially': 1, 'sun': 1, 'single': 1, 'best': 1, 'cherries': 1, 'each': 2, 'branches': 1, 'short': 1, 'ripe': 1, 'simultaneously': 1, 'all': 1, 'from': 1, 'energy': 1, 'because': 1, 'is': 2, 'world': 1, 's': 1, 'grown': 1, 'but': 1, 'called': 1, 'temperatures': 1, 'feet': 1, 'grows': 1, 'flowers': 1, 'pruned': 1, 'with': 2, 'in': 4, 'of': 1, 'on': 1, 'a': 3, 'can': 1, 'meters': 1, 'other': 1, 'cycle': 1, 'trees': 2, 'more': 1, 'aid': 1, 'green': 2, 'not': 1, 'region': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words calculation\n",
    "def calculateBOW(words):\n",
    "    return {word: words.count(word) for word in set(words)}\n",
    "\n",
    "bow1 = calculateBOW(l_doc1)\n",
    "print(\"Bag of Words Calculation: \\n\")\n",
    "print(bow1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44854b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words DataFrame: \n",
      "\n",
      "   along  are  waxy  soil  continuous  belt  high  shaded  covered  rain  ...  \\\n",
      "0      1    1     1     1           1     1     1       1        1     1  ...   \n",
      "\n",
      "   can  meters  other  cycle  trees  more  aid  green  not  region  \n",
      "0    1       1      1      1      2     1    1      2    1       1  \n",
      "\n",
      "[1 rows x 73 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words DataFrame: \\n\")\n",
    "df_bow = pd.DataFrame([bow1])\n",
    "print(df_bow,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18311c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 3 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 2 1 1 1 1 1 2 2 3 1 1 1 1 1 4 2\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 3 2 2 1 1 2 1]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([doc1])\n",
    "df_bow_sklearn = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print output\n",
    "print(X.toarray(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cd4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coffee': 4, 'trees': 2, 'are': 1, 'pruned': 1, 'short': 1, 'to': 3, 'conserve': 1, 'their': 1, 'energy': 1, 'and': 3, 'aid': 1, 'in': 4, 'harvesting': 1, 'but': 1, 'can': 1, 'grow': 3, 'more': 1, 'than': 1, '30': 1, 'feet': 1, '9': 1, 'meters': 1, 'high': 1, 'each': 2, 'tree': 2, 'is': 2, 'covered': 1, 'with': 2, 'green': 2, 'waxy': 1, 'leaves': 1, 'growing': 1, 'opposite': 1, 'other': 1, 'pairs': 1, 'cherries': 1, 'along': 1, 'the': 4, 'branches': 1, 'because': 1, 'it': 1, 'grows': 1, 'a': 3, 'continuous': 1, 'cycle': 1, 'itâ': 1, 's': 1, 'not': 1, 'unusual': 1, 'see': 1, 'flowers': 1, 'fruit': 2, 'ripe': 1, 'simultaneously': 1, 'on': 1, 'single': 1, 'all': 1, 'commercially': 1, 'grown': 1, 'from': 1, 'region': 1, 'of': 1, 'world': 1, 'called': 1, 'belt': 1, 'best': 1, 'rich': 1, 'soil': 1, 'mild': 1, 'temperatures': 1, 'frequent': 1, 'rain': 1, 'shaded': 1, 'sun': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Neha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK tokenization and word count\n",
    "nltk.download('punkt')\n",
    "dataset = [re.sub(r\"\\W\", ' ', sent) for sent in nltk.sent_tokenize(doc1)]\n",
    "word2count = {}\n",
    "for sentence in dataset:\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        word2count[word] = word2count.get(word, 0) + 1\n",
    "        \n",
    "\n",
    "print(word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42ce607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'along': 0, 'are': 1, 'waxy': 2, 'soil': 3, 'continuous': 4, 'belt': 5, 'high': 6, 'shaded': 7, 'covered': 8, 'rain': 9, 'rich': 10, 'harvesting': 11, 'the': 12, 'their': 13, 'coffee': 14, 'frequent': 15, 'than': 16, 'growing': 17, 'leaves': 18, 'opposite': 19, 'and': 20, 'unusual': 21, 'see': 22, 'fruit': 23, 'mild': 24, '9': 25, 'conserve': 26, '30': 27, 'it': 28, 'pairs': 29, 'grow': 30, 'to': 31, 'tree': 32, 'commercially': 33, 'sun': 34, 'single': 35, 'best': 36, 'cherries': 37, 'each': 38, 'branches': 39, 'short': 40, 'ripe': 41, 'simultaneously': 42, 'all': 43, 'from': 44, 'energy': 45, 'because': 46, 'is': 47, 'world': 48, 's': 49, 'grown': 50, 'but': 51, 'called': 52, 'temperatures': 53, 'feet': 54, 'grows': 55, 'flowers': 56, 'pruned': 57, 'with': 58, 'in': 59, 'of': 60, 'on': 61, 'a': 62, 'can': 63, 'meters': 64, 'other': 65, 'cycle': 66, 'trees': 67, 'more': 68, 'aid': 69, 'green': 70, 'not': 71, 'region': 72}\n"
     ]
    }
   ],
   "source": [
    "#Prepare word embeddings\n",
    "vocab_size = len(set(l_doc1))     #unique vocabulary size\n",
    "embed_dim = 10      #each word will be represented as a vector of 10 numbers\n",
    "\n",
    "#dictionary comprehension that creates a mapping of each unique word to a unique index.\n",
    "word_to_ix = {word: i for i, word in enumerate(set(l_doc1))}\n",
    "\n",
    "print(word_to_ix)\n",
    "\n",
    "embeddings = np.random.random_sample((vocab_size, embed_dim))\n",
    "\n",
    "#Context-target pairs for CBOW model\n",
    "data = [([l_doc1[i - 2], l_doc1[i - 1], l_doc1[i + 1], l_doc1[i + 2]], l_doc1[i]) \n",
    "        for i in range(2, len(l_doc1) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87428c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['coffee', 'trees', 'pruned', 'short'], 'are'), (['trees', 'are', 'short', 'to'], 'pruned'), (['are', 'pruned', 'to', 'conserve'], 'short'), (['pruned', 'short', 'conserve', 'their'], 'to'), (['short', 'to', 'their', 'energy'], 'conserve'), (['to', 'conserve', 'energy', 'and'], 'their'), (['conserve', 'their', 'and', 'aid'], 'energy'), (['their', 'energy', 'aid', 'in'], 'and'), (['energy', 'and', 'in', 'harvesting'], 'aid'), (['and', 'aid', 'harvesting', 'but'], 'in'), (['aid', 'in', 'but', 'can'], 'harvesting'), (['in', 'harvesting', 'can', 'grow'], 'but'), (['harvesting', 'but', 'grow', 'to'], 'can'), (['but', 'can', 'to', 'more'], 'grow'), (['can', 'grow', 'more', 'than'], 'to'), (['grow', 'to', 'than', '30'], 'more'), (['to', 'more', '30', 'feet'], 'than'), (['more', 'than', 'feet', '9'], '30'), (['than', '30', '9', 'meters'], 'feet'), (['30', 'feet', 'meters', 'high'], '9'), (['feet', '9', 'high', 'each'], 'meters'), (['9', 'meters', 'each', 'tree'], 'high'), (['meters', 'high', 'tree', 'is'], 'each'), (['high', 'each', 'is', 'covered'], 'tree'), (['each', 'tree', 'covered', 'with'], 'is'), (['tree', 'is', 'with', 'green'], 'covered'), (['is', 'covered', 'green', 'waxy'], 'with'), (['covered', 'with', 'waxy', 'leaves'], 'green'), (['with', 'green', 'leaves', 'growing'], 'waxy'), (['green', 'waxy', 'growing', 'opposite'], 'leaves'), (['waxy', 'leaves', 'opposite', 'each'], 'growing'), (['leaves', 'growing', 'each', 'other'], 'opposite'), (['growing', 'opposite', 'other', 'in'], 'each'), (['opposite', 'each', 'in', 'pairs'], 'other'), (['each', 'other', 'pairs', 'coffee'], 'in'), (['other', 'in', 'coffee', 'cherries'], 'pairs'), (['in', 'pairs', 'cherries', 'grow'], 'coffee'), (['pairs', 'coffee', 'grow', 'along'], 'cherries'), (['coffee', 'cherries', 'along', 'the'], 'grow'), (['cherries', 'grow', 'the', 'branches'], 'along'), (['grow', 'along', 'branches', 'because'], 'the'), (['along', 'the', 'because', 'it'], 'branches'), (['the', 'branches', 'it', 'grows'], 'because'), (['branches', 'because', 'grows', 'in'], 'it'), (['because', 'it', 'in', 'a'], 'grows'), (['it', 'grows', 'a', 'continuous'], 'in'), (['grows', 'in', 'continuous', 'cycle'], 'a'), (['in', 'a', 'cycle', 'it'], 'continuous'), (['a', 'continuous', 'it', 's'], 'cycle'), (['continuous', 'cycle', 's', 'not'], 'it'), (['cycle', 'it', 'not', 'unusual'], 's'), (['it', 's', 'unusual', 'to'], 'not'), (['s', 'not', 'to', 'see'], 'unusual'), (['not', 'unusual', 'see', 'flowers'], 'to'), (['unusual', 'to', 'flowers', 'green'], 'see'), (['to', 'see', 'green', 'fruit'], 'flowers'), (['see', 'flowers', 'fruit', 'and'], 'green'), (['flowers', 'green', 'and', 'ripe'], 'fruit'), (['green', 'fruit', 'ripe', 'fruit'], 'and'), (['fruit', 'and', 'fruit', 'simultaneously'], 'ripe'), (['and', 'ripe', 'simultaneously', 'on'], 'fruit'), (['ripe', 'fruit', 'on', 'a'], 'simultaneously'), (['fruit', 'simultaneously', 'a', 'single'], 'on'), (['simultaneously', 'on', 'single', 'tree'], 'a'), (['on', 'a', 'tree', 'all'], 'single'), (['a', 'single', 'all', 'commercially'], 'tree'), (['single', 'tree', 'commercially', 'grown'], 'all'), (['tree', 'all', 'grown', 'coffee'], 'commercially'), (['all', 'commercially', 'coffee', 'is'], 'grown'), (['commercially', 'grown', 'is', 'from'], 'coffee'), (['grown', 'coffee', 'from', 'a'], 'is'), (['coffee', 'is', 'a', 'region'], 'from'), (['is', 'from', 'region', 'of'], 'a'), (['from', 'a', 'of', 'the'], 'region'), (['a', 'region', 'the', 'world'], 'of'), (['region', 'of', 'world', 'called'], 'the'), (['of', 'the', 'called', 'the'], 'world'), (['the', 'world', 'the', 'coffee'], 'called'), (['world', 'called', 'coffee', 'belt'], 'the'), (['called', 'the', 'belt', 'the'], 'coffee'), (['the', 'coffee', 'the', 'trees'], 'belt'), (['coffee', 'belt', 'trees', 'grow'], 'the'), (['belt', 'the', 'grow', 'best'], 'trees'), (['the', 'trees', 'best', 'in'], 'grow'), (['trees', 'grow', 'in', 'rich'], 'best'), (['grow', 'best', 'rich', 'soil'], 'in'), (['best', 'in', 'soil', 'with'], 'rich'), (['in', 'rich', 'with', 'mild'], 'soil'), (['rich', 'soil', 'mild', 'temperatures'], 'with'), (['soil', 'with', 'temperatures', 'frequent'], 'mild'), (['with', 'mild', 'frequent', 'rain'], 'temperatures'), (['mild', 'temperatures', 'rain', 'and'], 'frequent'), (['temperatures', 'frequent', 'and', 'shaded'], 'rain'), (['frequent', 'rain', 'shaded', 'sun'], 'and')]\n",
      "[[0.6808703  0.38521844 0.84839182 0.71324505 0.84777767 0.18244394\n",
      "  0.07430895 0.14976843 0.36148325 0.85984874]\n",
      " [0.97173124 0.8140323  0.91618635 0.03445404 0.06264607 0.04089945\n",
      "  0.97323261 0.76010082 0.36358315 0.98082526]\n",
      " [0.64605805 0.46418478 0.94253117 0.39886907 0.49210309 0.28178432\n",
      "  0.59984282 0.19296825 0.54913888 0.60305053]\n",
      " [0.93252542 0.73418182 0.91424006 0.07316783 0.90571123 0.86323552\n",
      "  0.87194599 0.16767196 0.09699554 0.34660338]\n",
      " [0.77370657 0.22954354 0.89040779 0.13891569 0.7856164  0.59576805\n",
      "  0.62170026 0.70774939 0.52628858 0.07548488]\n",
      " [0.70588139 0.73529257 0.04901379 0.9348477  0.94528523 0.41246297\n",
      "  0.48870073 0.09565822 0.79026195 0.62391355]\n",
      " [0.02289184 0.05311175 0.27451508 0.25151894 0.72992086 0.74839103\n",
      "  0.17822112 0.95524424 0.53208962 0.9851876 ]\n",
      " [0.47181788 0.83298312 0.38294727 0.84203933 0.82905247 0.39791318\n",
      "  0.28054398 0.25379155 0.0343202  0.0784172 ]\n",
      " [0.38191389 0.47844492 0.69206712 0.80481764 0.80770066 0.48682451\n",
      "  0.68066926 0.52553325 0.53716983 0.27361099]\n",
      " [0.91220458 0.68455194 0.78985363 0.02541607 0.14083468 0.17361917\n",
      "  0.57327887 0.67880898 0.50344589 0.01618974]\n",
      " [0.54479854 0.71132492 0.16789688 0.27471201 0.5813274  0.98915554\n",
      "  0.7410777  0.90121303 0.41689811 0.88402873]\n",
      " [0.63949811 0.16081422 0.70973236 0.73121109 0.13956331 0.02343943\n",
      "  0.06525361 0.06560969 0.37070753 0.7669157 ]\n",
      " [0.57883256 0.64425757 0.29666078 0.86430086 0.97781787 0.56883471\n",
      "  0.51596925 0.02382458 0.43772873 0.67410317]\n",
      " [0.5027039  0.28257451 0.1175295  0.2395061  0.48771546 0.42187086\n",
      "  0.02732999 0.41643432 0.98054276 0.7356126 ]\n",
      " [0.25322248 0.74724384 0.21902242 0.24561032 0.03668512 0.5819117\n",
      "  0.30300862 0.21256191 0.27406193 0.81535611]\n",
      " [0.55951259 0.49732383 0.07958608 0.81803915 0.10997251 0.65706853\n",
      "  0.13255837 0.55966323 0.98726377 0.19068078]\n",
      " [0.38732943 0.10912497 0.25216142 0.87805572 0.99768836 0.76967589\n",
      "  0.9312281  0.68539882 0.60437629 0.08304503]\n",
      " [0.1396653  0.28945484 0.39077788 0.97523312 0.63013904 0.18675744\n",
      "  0.33573712 0.31264498 0.68333646 0.89612365]\n",
      " [0.9385131  0.23063658 0.04147946 0.04560644 0.54150892 0.59415852\n",
      "  0.55122367 0.42487981 0.01464326 0.80080412]\n",
      " [0.45917836 0.07621584 0.99787625 0.7109429  0.28106289 0.49229486\n",
      "  0.41981443 0.76143767 0.87900945 0.53713058]\n",
      " [0.07117285 0.62144889 0.40904704 0.17716102 0.82569661 0.56632545\n",
      "  0.16218871 0.73656123 0.53309183 0.51293251]\n",
      " [0.02405024 0.66563518 0.2197474  0.86982521 0.7503608  0.80948763\n",
      "  0.68020506 0.88222595 0.83613832 0.24573666]\n",
      " [0.51489944 0.2105336  0.3783063  0.36349322 0.84686833 0.34886975\n",
      "  0.53711325 0.60464262 0.31732186 0.01533951]\n",
      " [0.54829125 0.46195486 0.91564523 0.75962625 0.10271025 0.45993902\n",
      "  0.6654925  0.87427074 0.32688532 0.38713205]\n",
      " [0.82672455 0.13211899 0.41047641 0.71361283 0.00382336 0.52323472\n",
      "  0.01814117 0.01161104 0.29741061 0.98034183]\n",
      " [0.98564745 0.89567479 0.61365386 0.08699183 0.09279701 0.95264692\n",
      "  0.91201548 0.29359891 0.55953371 0.24968702]\n",
      " [0.23076024 0.12382629 0.23871099 0.61764501 0.49891786 0.92897759\n",
      "  0.38967875 0.18337356 0.17069761 0.76701494]\n",
      " [0.9298438  0.91947869 0.55086956 0.1459871  0.6750144  0.07762513\n",
      "  0.95829514 0.11978255 0.37118421 0.89000303]\n",
      " [0.88142564 0.02833945 0.99240737 0.94106177 0.90250999 0.65347785\n",
      "  0.49360345 0.38542551 0.07178375 0.81703238]\n",
      " [0.7728964  0.42604727 0.25121861 0.22515029 0.91053449 0.84695084\n",
      "  0.49330649 0.69286908 0.60908703 0.55783578]\n",
      " [0.1054137  0.81719456 0.05901704 0.81434487 0.07151623 0.23253179\n",
      "  0.27425683 0.48327927 0.11038734 0.1642023 ]\n",
      " [0.04344963 0.19804538 0.80628405 0.66275997 0.46351926 0.94934173\n",
      "  0.04281209 0.58223275 0.88616287 0.92286179]\n",
      " [0.24431609 0.57358148 0.58218033 0.38003835 0.47322353 0.96427408\n",
      "  0.56285855 0.92732799 0.59936037 0.65309483]\n",
      " [0.55896598 0.9791925  0.07322059 0.65560631 0.71640836 0.46622716\n",
      "  0.46666401 0.32932929 0.3338435  0.28589892]\n",
      " [0.27142535 0.88075339 0.60732385 0.67163196 0.17844929 0.61913936\n",
      "  0.04086683 0.6819618  0.43004453 0.94509973]\n",
      " [0.97160336 0.39113768 0.43415701 0.62104751 0.11052654 0.49692361\n",
      "  0.6538327  0.32220085 0.25689363 0.99991505]\n",
      " [0.82030835 0.60089089 0.85304427 0.67485734 0.35382599 0.63662477\n",
      "  0.53227709 0.87721807 0.53215932 0.10003566]\n",
      " [0.03853683 0.95469996 0.95421584 0.96469646 0.25592756 0.86450997\n",
      "  0.87310499 0.88115671 0.20374016 0.12298938]\n",
      " [0.81299797 0.18962435 0.07477225 0.12020103 0.63181295 0.37999359\n",
      "  0.39318168 0.17696337 0.25995826 0.52152035]\n",
      " [0.43222922 0.95382441 0.554313   0.95056044 0.92620312 0.18332812\n",
      "  0.70280019 0.50009737 0.46337058 0.03759981]\n",
      " [0.05544622 0.81729851 0.54749084 0.33492854 0.21195204 0.70146876\n",
      "  0.25574435 0.06000786 0.11662802 0.97682806]\n",
      " [0.78416259 0.07957978 0.22008951 0.60427911 0.67333882 0.93697979\n",
      "  0.13971391 0.73575226 0.26600932 0.83009435]\n",
      " [0.52831863 0.33808493 0.22768972 0.73696418 0.91649795 0.57494792\n",
      "  0.93962914 0.87516644 0.666779   0.39943805]\n",
      " [0.6027426  0.70276518 0.61657507 0.2384685  0.85857983 0.98301511\n",
      "  0.70441896 0.99891724 0.16505783 0.98209583]\n",
      " [0.64470271 0.00239249 0.28285017 0.88348601 0.48587746 0.52426022\n",
      "  0.82066714 0.36397254 0.96335874 0.18202808]\n",
      " [0.1638136  0.72390959 0.63675749 0.00947832 0.44564215 0.1746389\n",
      "  0.75241906 0.95384611 0.47452813 0.86444014]\n",
      " [0.66056613 0.63738216 0.56675204 0.69504515 0.56633698 0.87175943\n",
      "  0.12349691 0.5803708  0.33162533 0.75028632]\n",
      " [0.50464858 0.60333043 0.85937019 0.64031778 0.51620837 0.62422954\n",
      "  0.85881473 0.27989602 0.28220641 0.75349699]\n",
      " [0.30409235 0.83748899 0.51753617 0.50451644 0.3155651  0.68866351\n",
      "  0.2405154  0.2294526  0.689401   0.69515729]\n",
      " [0.87471098 0.25803397 0.34873696 0.25944793 0.79733987 0.22613349\n",
      "  0.83620585 0.62257206 0.76174034 0.45742714]\n",
      " [0.50282295 0.0414011  0.72332203 0.40449249 0.5890399  0.31204509\n",
      "  0.01612624 0.13349608 0.75786718 0.54682916]\n",
      " [0.83664545 0.12775913 0.88009837 0.26292886 0.20306857 0.21479759\n",
      "  0.9231398  0.26774998 0.82114158 0.78589556]\n",
      " [0.21663158 0.53552913 0.30259254 0.47725382 0.81429051 0.82472708\n",
      "  0.41089648 0.48766395 0.63571862 0.26233143]\n",
      " [0.2333276  0.70102797 0.33367811 0.55555226 0.51263557 0.7885587\n",
      "  0.73210534 0.7989383  0.27003364 0.57445446]\n",
      " [0.75989572 0.52861836 0.30963807 0.82754556 0.38676158 0.50806493\n",
      "  0.22934627 0.03841421 0.60284682 0.72586253]\n",
      " [0.26043867 0.97964073 0.22625447 0.53789309 0.32989555 0.64677173\n",
      "  0.19227319 0.22500487 0.11755072 0.29597056]\n",
      " [0.78959858 0.45604819 0.78788021 0.30042621 0.94661002 0.01321355\n",
      "  0.66961672 0.90059111 0.72007226 0.69951113]\n",
      " [0.89907824 0.63274926 0.90540287 0.1577034  0.09434761 0.3405121\n",
      "  0.45507232 0.86399965 0.11620063 0.16426615]\n",
      " [0.1966234  0.71554003 0.82598151 0.83523348 0.00542665 0.79430825\n",
      "  0.7316427  0.0100336  0.83743785 0.99094691]\n",
      " [0.30923653 0.39655187 0.72759436 0.23943013 0.74195144 0.06590609\n",
      "  0.48965557 0.05603764 0.33769394 0.93659616]\n",
      " [0.97533132 0.97742493 0.46894578 0.28823277 0.14541966 0.73589546\n",
      "  0.61805889 0.84351862 0.79408115 0.33849081]\n",
      " [0.07465175 0.97813538 0.4330298  0.50707457 0.49623716 0.52647104\n",
      "  0.67884849 0.57594484 0.99214091 0.46625411]\n",
      " [0.55690298 0.24172242 0.82571526 0.84725229 0.13262053 0.21074937\n",
      "  0.2052114  0.97342242 0.20606871 0.8955077 ]\n",
      " [0.01771818 0.77013536 0.68134675 0.20756775 0.55514911 0.24583851\n",
      "  0.22696169 0.05993475 0.48596274 0.57949501]\n",
      " [0.48921745 0.21450285 0.17003635 0.34388402 0.57409869 0.40810048\n",
      "  0.25325679 0.68734606 0.10625043 0.24533947]\n",
      " [0.35392514 0.17901229 0.32339144 0.04070379 0.96316135 0.116403\n",
      "  0.43678757 0.52893444 0.23519955 0.60884002]\n",
      " [0.77269504 0.21932556 0.46271485 0.95991064 0.38895684 0.41244978\n",
      "  0.49508656 0.29052494 0.4046255  0.62067164]\n",
      " [0.76636047 0.08722023 0.0673096  0.49252146 0.87941328 0.26449627\n",
      "  0.49676396 0.05743222 0.18429225 0.17437601]\n",
      " [0.25896417 0.16274858 0.33268011 0.12829885 0.56515407 0.85919428\n",
      "  0.29844545 0.04980813 0.70550937 0.07041927]\n",
      " [0.68655047 0.06688879 0.86024777 0.91710003 0.08493178 0.37426014\n",
      "  0.81538641 0.80096985 0.84318044 0.0541865 ]\n",
      " [0.6648189  0.91926476 0.67934598 0.34426495 0.09723017 0.15553858\n",
      "  0.7938806  0.2298532  0.99284067 0.08414024]\n",
      " [0.98076504 0.46583749 0.1945374  0.76361158 0.13515491 0.05830848\n",
      "  0.00624216 0.43859271 0.94950338 0.09735918]\n",
      " [0.04694317 0.8813989  0.10307688 0.04014277 0.41644069 0.10276123\n",
      "  0.92149594 0.54169078 0.13649071 0.26038417]]\n"
     ]
    }
   ],
   "source": [
    "#Print example context-target pairs and embeddings\n",
    "print(data)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d4fbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14, 67, 57, 40], [67, 1, 40, 31], [1, 57, 31, 26], [57, 40, 26, 13], [40, 31, 13, 45], [31, 26, 45, 20], [26, 13, 20, 69], [13, 45, 69, 59], [45, 20, 59, 11], [20, 69, 11, 51], [69, 59, 51, 63], [59, 11, 63, 30], [11, 51, 30, 31], [51, 63, 31, 68], [63, 30, 68, 16], [30, 31, 16, 27], [31, 68, 27, 54], [68, 16, 54, 25], [16, 27, 25, 64], [27, 54, 64, 6], [54, 25, 6, 38], [25, 64, 38, 32], [64, 6, 32, 47], [6, 38, 47, 8], [38, 32, 8, 58], [32, 47, 58, 70], [47, 8, 70, 2], [8, 58, 2, 18], [58, 70, 18, 17], [70, 2, 17, 19], [2, 18, 19, 38], [18, 17, 38, 65], [17, 19, 65, 59], [19, 38, 59, 29], [38, 65, 29, 14], [65, 59, 14, 37], [59, 29, 37, 30], [29, 14, 30, 0], [14, 37, 0, 12], [37, 30, 12, 39], [30, 0, 39, 46], [0, 12, 46, 28], [12, 39, 28, 55], [39, 46, 55, 59], [46, 28, 59, 62], [28, 55, 62, 4], [55, 59, 4, 66], [59, 62, 66, 28], [62, 4, 28, 49], [4, 66, 49, 71], [66, 28, 71, 21], [28, 49, 21, 31], [49, 71, 31, 22], [71, 21, 22, 56], [21, 31, 56, 70], [31, 22, 70, 23], [22, 56, 23, 20], [56, 70, 20, 41], [70, 23, 41, 23], [23, 20, 23, 42], [20, 41, 42, 61], [41, 23, 61, 62], [23, 42, 62, 35], [42, 61, 35, 32], [61, 62, 32, 43], [62, 35, 43, 33], [35, 32, 33, 50], [32, 43, 50, 14], [43, 33, 14, 47], [33, 50, 47, 44], [50, 14, 44, 62], [14, 47, 62, 72], [47, 44, 72, 60], [44, 62, 60, 12], [62, 72, 12, 48], [72, 60, 48, 52], [60, 12, 52, 12], [12, 48, 12, 14], [48, 52, 14, 5], [52, 12, 5, 12], [12, 14, 12, 67], [14, 5, 67, 30], [5, 12, 30, 36], [12, 67, 36, 59], [67, 30, 59, 10], [30, 36, 10, 3], [36, 59, 3, 58], [59, 10, 58, 24], [10, 3, 24, 53], [3, 58, 53, 15], [58, 24, 15, 9], [24, 53, 9, 20], [53, 15, 20, 7], [15, 9, 7, 34]]\n",
      "[1, 57, 40, 31, 26, 13, 45, 20, 69, 59, 11, 51, 63, 30, 31, 68, 16, 27, 54, 25, 64, 6, 38, 32, 47, 8, 58, 70, 2, 18, 17, 19, 38, 65, 59, 29, 14, 37, 30, 0, 12, 39, 46, 28, 55, 59, 62, 4, 66, 28, 49, 71, 21, 31, 22, 56, 70, 23, 20, 41, 23, 42, 61, 62, 35, 32, 43, 33, 50, 14, 47, 44, 62, 72, 60, 12, 48, 52, 12, 14, 5, 12, 67, 30, 36, 59, 10, 3, 58, 24, 53, 15, 9, 20]\n"
     ]
    }
   ],
   "source": [
    "# Convert context words to indices\n",
    "context_indices = [[word_to_ix[word] for word in context] for context, _ in data]\n",
    "target_indices = [word_to_ix[target] for _, target in data]\n",
    "\n",
    "print(context_indices)\n",
    "print(target_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "707998ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 4.2942\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 4.2871 \n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0106 - loss: 4.2822     \n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0106 - loss: 4.2751     \n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0539 - loss: 4.2690 \n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0958 - loss: 4.2635 \n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1682 - loss: 4.2576 \n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1828 - loss: 4.2518 \n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2225 - loss: 4.2463 \n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2633 - loss: 4.2430 \n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2988 - loss: 4.2355 \n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3343 - loss: 4.2284 \n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3708 - loss: 4.2211 \n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4053 - loss: 4.2149 \n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4056 - loss: 4.2091 \n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4279 - loss: 4.2025 \n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4620 - loss: 4.1912 \n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4570 - loss: 4.1879 \n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5696 - loss: 4.1772 \n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5514 - loss: 4.1717 \n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5752 - loss: 4.1603 \n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6380 - loss: 4.1525 \n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6671 - loss: 4.1425 \n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6881 - loss: 4.1301 \n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6753 - loss: 4.1274 \n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7065 - loss: 4.1119 \n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 4.0994 \n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 4.0877 \n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7484 - loss: 4.0741 \n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 4.0643 \n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7747 - loss: 4.0442 \n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7580 - loss: 4.0362 \n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7686 - loss: 4.0216 \n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 4.0051 \n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 3.9898 \n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8382 - loss: 3.9754 \n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8669 - loss: 3.9639 \n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8840 - loss: 3.9432 \n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9063 - loss: 3.9107 \n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8921 - loss: 3.9147 \n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8818 - loss: 3.8912 \n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9198 - loss: 3.8700 \n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 3.8483 \n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9539 - loss: 3.8193 \n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9709 - loss: 3.7920 \n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9489 - loss: 3.7786 \n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 3.7504 \n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9737 - loss: 3.7332 \n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9659 - loss: 3.7154 \n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 3.6889 \n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 3.6546 \n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 3.6301 \n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 3.6022 \n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 3.5667 \n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 3.5376 \n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 3.5089 \n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 3.4843 \n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 3.4460 \n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 3.4147 \n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 3.3792 \n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 3.3617 \n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 3.3058 \n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9815 - loss: 3.2677 \n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 3.2442 \n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 3.2042 \n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9776 - loss: 3.1813 \n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 3.1245 \n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 3.0766 \n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 3.0450 \n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 3.0018 \n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 2.9487 \n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 2.9410 \n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 2.8778 \n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 2.8336 \n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 2.7909 \n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 2.7565 \n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.6973 \n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6630 \n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 2.6136\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5879 \n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5036 \n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.4737 \n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4240 \n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3554 \n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3516\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2861 \n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2341 \n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.1992 \n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1195 \n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0754 \n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0234 \n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.9985 \n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.9347 \n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8903 \n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8284 \n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7877 \n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7245 \n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7094 \n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6322 \n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6057 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "Predicted word: simultaneously\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(context_indices)\n",
    "y_train = np.array(target_indices)\n",
    "\n",
    "# Define the CBOW model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=4))  # 4 context words\n",
    "model.add(Flatten())\n",
    "model.add(Dense(vocab_size, activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "\n",
    "# Example context for prediction\n",
    "example_context = ['coffee', 'fruit', 'rain', 'waxy']\n",
    "example_context_indices = np.array([[word_to_ix[word] for word in example_context]])\n",
    "\n",
    "# Predict\n",
    "predicted = model.predict(example_context_indices)\n",
    "predicted_word_index = np.argmax(predicted, axis=-1)\n",
    "predicted_word = list(word_to_ix.keys())[predicted_word_index[0]]\n",
    "print(f\"Predicted word: {predicted_word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
